{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+--------+--------+------------+------------+------+----------+-------------+--------------------+------------------------+------------+----------------+--------------------+----------------+-----------------------+--------------+-------------+\n",
      "|   uid|national_identifier|   first|    last|mother_first|father_first|gender|birth_city|date_of_birth|id_registration_city|id_registration_district|address_city|address_district|address_neighborhood|  street_address|door_or_entrance_number|month_of_birth|year_of_birth|\n",
      "+------+-------------------+--------+--------+------------+------------+------+----------+-------------+--------------------+------------------------+------------+----------------+--------------------+----------------+-----------------------+--------------+-------------+\n",
      "|291990|        23480340824|NESLIHAN|  ZENGIN|      ZEYCAN|       OSMAN|     K|    KANGAL|   1978-06-10|             MALATYA|                KULUNCAK|     MALATYA|        KULUNCAK|      ISMETPASA MAH.|BOGAZICI CADDESI|                     14|             6|         1978|\n",
      "|291991|        17111553172|   SADET|YILDIRIM|       ZOHRE|      ISMAIL|     K|    MERSIN|   1949-08-03|             MALATYA|                KULUNCAK|     MALATYA|        KULUNCAK|      ISMETPASA MAH.| CITILBAGI SOKAK|                     40|             8|         1949|\n",
      "|291992|        10499773538|   GONUL|   CETIN|        ESME|      HALIFE|     K|  KULUNCAK|   1987-08-15|             MALATYA|                 AKCADAG|     MALATYA|        KULUNCAK|      ISMETPASA MAH.|BOGAZICI CADDESI|                      2|             8|         1987|\n",
      "+------+-------------------+--------+--------+------------+------------+------+----------+-------------+--------------------+------------------------+------------+----------------+--------------------+----------------+-----------------------+--------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import re\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank, col\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import RFormula\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "# import spark.implicits._\n",
    "\n",
    "\n",
    "sparkconf = SparkConf().setAppName('Mernis')\n",
    "sparkconf.set('spark.executor.memory','10g')\n",
    "sparkconf.set('spark.driver.memory','10g')\n",
    "sparkconf.set(\"spark.sql.debug.maxToStringFields\", \"100\")\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"Mernis\")\n",
    "         .config(conf=sparkconf)\n",
    "         .getOrCreate())\n",
    "\n",
    "# sc = SparkContext.getOrCreate()\n",
    "# 加载数据\n",
    "file_path = '/root/myfile/mernis/data_dump.sql'\n",
    "\n",
    "data = spark.sparkContext.textFile(file_path). \\\n",
    "    filter((lambda line: re.findall('^\\d{6}', line))). \\\n",
    "    map(lambda line: line.split('\\t')[:-1])\n",
    "\n",
    "schema = \"uid STRING, national_identifier STRING, first STRING, last STRING, mother_first STRING, \" \\\n",
    "         \"father_first STRING, gender STRING, birth_city STRING, date_of_birth STRING, \" \\\n",
    "         \"id_registration_city STRING, id_registration_district STRING, address_city STRING, \" \\\n",
    "         \"address_district STRING, address_neighborhood STRING,street_address STRING, \" \\\n",
    "         \"door_or_entrance_number STRING\"\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "# total_count = df.count()  # total_count = 49611709\n",
    "# print(\"The total number:\", total_count)\n",
    "\n",
    "\n",
    "def format_date(line):\n",
    "    li = line.split('/')\n",
    "    if len(li[2]) == 4 and 0 < len(li[1]) <= 2 and 0 < len(li[1]) <= 2:\n",
    "        return li[2] + '-' + li[1].zfill(2) + '-' + li[0].zfill(2)\n",
    "    else:\n",
    "        return 'null'\n",
    "\n",
    "\n",
    "format_date_udf = udf(format_date, returnType=StringType())\n",
    "\n",
    "df.createOrReplaceTempView('citizens')\n",
    "df_format_date = df.withColumn(\"date_of_birth\", format_date_udf(df[\"date_of_birth\"]))\n",
    "df_format_date = df_format_date.filter(expr(\"\"\"date_of_birth != 'null'\"\"\"))\n",
    "df_format_date = df_format_date.withColumn('date_of_birth', to_date('date_of_birth')).\\\n",
    "    withColumn('month_of_birth', month('date_of_birth')).\\\n",
    "    withColumn('year_of_birth', year('date_of_birth'))\n",
    "df_format_date.show(3)\n",
    "\n",
    "# df_age = df_format_date.withColumn('age', (round(months_between(\n",
    "#         to_date(lit('2009-12-31')), col('date_of_birth')) / 12, 0)).cast('float'))\n",
    "# df_age.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+-----+-------+\n",
      "|address_city|  total| area| desity|\n",
      "+------------+-------+-----+-------+\n",
      "|     ANTALYA|1288425| 1417| 909.26|\n",
      "|     KOCAELI|1017832| 3418| 297.79|\n",
      "|    ISTANBUL|8821021| 5343|1650.95|\n",
      "|       IZMIR|2787611| 7340| 379.78|\n",
      "|       AYDIN|1410156| 8007| 176.12|\n",
      "|       BURSA|1782462|10891| 163.66|\n",
      "|       ADANA|1388836|14030|  98.99|\n",
      "|      MERSIN|1097789|15737|  69.76|\n",
      "|      ANKARA|3077939|30715| 100.21|\n",
      "|       KONYA|1330357|38257|  34.77|\n",
      "+------------+-------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # N6\n",
    "\n",
    "# The top10 city with most citizens\n",
    "df_n6 = df_format_date.\\\n",
    "    select('address_city').\\\n",
    "    groupBy('address_city').\\\n",
    "    agg(count('*').alias('total')).\\\n",
    "    orderBy('total',ascending=False).\\\n",
    "    limit(10)\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "area = [('ADANA',14030),('ISTANBUL',5343),('BURSA',10891),('IZMIR',7340),('AYDIN',8007),\\\n",
    "       ('ANKARA',30715),('ANTALYA',1417),('KOCAELI',3418),('KONYA',38257),('MERSIN',15737)]\n",
    "\n",
    "df_area = spark.createDataFrame(area,['address_city','area'])\n",
    "df_area = df_n6.join(df_area,'address_city','left_outer').orderBy('area')\n",
    "df_area.show(10)\n",
    "density_df = df_area.withColumn('desity',round(df_area['total'] / df_area['area'],2) )\n",
    "density_df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of cross-district floating population:0.523\n",
      "Proportion of cross-city floating population:0.361\n"
     ]
    }
   ],
   "source": [
    "total_num = 49611709\n",
    "df_n7_district = df_format_date.\\\n",
    "    select('id_registration_district','address_district').\\\n",
    "    filter(col('id_registration_district')!=col('address_district'))\n",
    "print(type(df_n7_district.count()))\n",
    "propor_district = df_n7_district.count() / total_num\n",
    "print('Proportion of cross-district floating population:%.3f'%propor_district)\n",
    "\n",
    "df_n7_city = df_format_date.\\\n",
    "    select('id_registration_city','address_city').\\\n",
    "    filter(col('id_registration_city')!=col('address_city'))\n",
    "propor_city = df_n7_city.count() / total_num\n",
    "print('Proportion of cross-city floating population:%.3f'%propor_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将出生日期中的年和月提取出来构成新的列,'year_of_birth'和'month_of_birth'，以便于转换成特征。由于总的数据量过大，从中抽取出4900余份样本进行训练和预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+-----------------+--------+------------+------------+------+----------+-------------+--------------------+------------------------+------------+----------------+--------------------+--------------------+-----------------------+--------------+-------------+\n",
      "|   uid|national_identifier|            first|    last|mother_first|father_first|gender|birth_city|date_of_birth|id_registration_city|id_registration_district|address_city|address_district|address_neighborhood|      street_address|door_or_entrance_number|month_of_birth|year_of_birth|\n",
      "+------+-------------------+-----------------+--------+------------+------------+------+----------+-------------+--------------------+------------------------+------------+----------------+--------------------+--------------------+-----------------------+--------------+-------------+\n",
      "|301613|        19211135418|            ERKAN|  BOZBAY|      CIGDEM|     MUSTAFA|     E| YESILYURT|   1980-04-14|             MALATYA|       YESILYURT/MALATYA|     MALATYA|  MALATYA MERKEZ|       ASLANBEY MAH.|           1.. SOKAK|                   11 A|             4|         1980|\n",
      "|321286|        20933426784|           MERYEM|   AGKOC|       HANEY|    ALISEYDI|     K|   MALATYA|   1966-03-02|             MALATYA|          MALATYA MERKEZ|     MALATYA|  MALATYA MERKEZ|        BEYDAGI MAH.|  18.SK. 2.ARA SOKAK|                     15|             3|         1966|\n",
      "|352067|        40765866114|       ABDURRAHIM|KANSIRAY|      MERYEM|      SEHMUS|     E|     SAVUR|   1972-11-02|              MARDIN|                   SAVUR|     MALATYA|  MALATYA MERKEZ|         COSNUK MAH.|NECIP FAZIL KISAK...|                      8|            11|         1972|\n",
      "|353390|        28066584470|            ZAFER|   DEMIR|      HACERE|       YUSUF|     E|    ELAZIG|   1985-10-18|              ELAZIG|           ELAZIG MERKEZ|     MALATYA|  MALATYA MERKEZ|         COSNUK MAH.|NECIP FAZIL KISAK...|                      2|            10|         1985|\n",
      "|354531|        55177286696|           BULENT|   SERCE|    HAMIDIYE|     HUSEYIN|     E|   MALATYA|   1972-07-16|             MALATYA|          MALATYA MERKEZ|     MALATYA|  MALATYA MERKEZ|         COSNUK MAH.|          CAMI SOKAK|                     30|             7|         1972|\n",
      "|364781|        54154306570|             AYSE| KARAKUS|     FIRDEVS|  HACI BEKIR|     K| YESILYURT|   1947-08-15|             MALATYA|                 AKCADAG|     MALATYA|  MALATYA MERKEZ|         KERNEK MAH.|SHT. HAMIT FENDOG...|                     11|             8|         1947|\n",
      "|370973|        58036230434|           SERDAR|  YILDIZ|  UMMUGULSUM|      MEVLUT|     E|    KESKIN|   1975-01-01|           KIRIKKALE|                  CELEBI|     MALATYA|  MALATYA MERKEZ|          FIRAT MAH.|           3.. SOKAK|                     41|             1|         1975|\n",
      "|385295|        15398611318|            AHMET|   EVEGU|       HANIM|      BATTAL|     E|   MALATYA|   1987-09-05|             MALATYA|          MALATYA MERKEZ|     MALATYA|  MALATYA MERKEZ|        GOZTEPE MAH.|  1.SOK. 2.ARA SOKAK|                      1|             9|         1987|\n",
      "|456750|        11744733246|ABDULVAHAP TUNCAY|   TOKAC|      NURHAN|      NEVZAT|     E|   MALATYA|   1964-03-05|             MALATYA|          MALATYA MERKEZ|     MALATYA|  MALATYA MERKEZ|        OZALPER MAH.|T.OZAL 1.CAD.8 SOKAK|                      4|             3|         1964|\n",
      "|469793|        16493226452|           SAZIYE|   DUMAN|       EMINE|     HUSEYIN|     K|   MALATYA|   1959-12-13|             MALATYA|       YESILYURT/MALATYA|     MALATYA|  MALATYA MERKEZ|        SAMANLI MAH.|           14. SOKAK|                      3|            12|         1959|\n",
      "+------+-------------------+-----------------+--------+------------+------------+------+----------+-------------+--------------------+------------------------+------------+----------------+--------------------+--------------------+-----------------------+--------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "2535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[uid: string, national_identifier: string, first: string, last: string, mother_first: string, father_first: string, gender: string, birth_city: string, date_of_birth: date, id_registration_city: string, id_registration_district: string, address_city: string, address_district: string, address_neighborhood: string, street_address: string, door_or_entrance_number: string, month_of_birth: int, year_of_birth: int, gender_Index: double, birth_city_Index: double, address_neighborhood_Index: double, last_Index: double, address_city_Index: double, id_registration_city_Index: double, month_of_birth_Index: double, father_first_Index: double, address_district_Index: double, first_Index: double, street_address_Index: double, year_of_birth_Index: double, mother_first_Index: double, id_registration_district_Index: double, address_city_OHE: vector, id_registration_district_OHE: vector, month_of_birth_OHE: vector, birth_city_OHE: vector, father_first_OHE: vector, id_registration_city_OHE: vector, first_OHE: vector, street_address_OHE: vector, gender_OHE: vector, year_of_birth_OHE: vector, address_neighborhood_OHE: vector, last_OHE: vector, mother_first_OHE: vector, address_district_OHE: vector]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_h1 = df_format_date.sample(False, 0.00005, seed = 2018)\n",
    "df_h1.show(10)\n",
    "df_h1 = df_h1.dropna()\n",
    "print(df_h1.count())\n",
    "feature_col = ['first','last','mother_first','father_first','gender','birth_city',\n",
    "               'month_of_birth','year_of_birth','id_registration_city', 'id_registration_district',\n",
    "               'address_district','address_neighborhood', 'street_address','address_city'\n",
    "               ]\n",
    "\n",
    "indexOutputCols = [x + '_Index' for x in feature_col]\n",
    "oheOutputCols = [x + '_OHE' for x in feature_col]\n",
    "stringIndexer_features = StringIndexer(inputCols=feature_col,outputCols=indexOutputCols,\n",
    "                              handleInvalid=\"skip\")\n",
    "oheEncoder_features = OneHotEncoder(inputCols=indexOutputCols,outputCols=oheOutputCols)\n",
    "\n",
    "# stringIndexer_labels = StringIndexer(inputCols=['address_city'],outputCols=['address_city_Index'])\n",
    "# oheEncoder_labels = OneHotEncoder(inputCols=['address_city_Index'],outputCols=['address_city_OHE'])\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages=[stringIndexer_features,oheEncoder_features])\n",
    "model = pipeline.fit(df_h1)\n",
    "res = model.transform(df_h1)\n",
    "\n",
    "# Split the dataset into training, validation and test set with prob 0.7,0.2 and 0.1.\n",
    "(trainingData, validData, testData) = res.randomSplit([0.7, 0.2,0.1], seed=100)\n",
    "# trainingData.persist()\n",
    "# validData.persist()\n",
    "# testData.persist()\n",
    "# print('Training Dataset Count:{}'.format(trainingData.count()))\n",
    "# print('Vaildation Dataset Count:{}'.format(validData.count()))\n",
    "# print('Test Dataset Count:{}'.format(testData.count()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=oheOutputCols, outputCol='features')\n",
    "res2 = vecAssembler.transform(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# # H1. 某人所在城市的预测模型：给定一个人的所有信息（除了所在城市），预测这个人所在的城市。 分析该模型Top1到 Top\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# 增加一列labels， 保留address_city的onehot编码\n",
    "feature_col = ['first','last','mother_first','father_first','gender','birth_city',\n",
    "               'month_of_birth','year_of_birth','id_registration_city', 'id_registration_district',\n",
    "               'address_district','address_neighborhood', 'street_address'\n",
    "               ]\n",
    "\n",
    "# All the feature columns\n",
    "oheOutputCols = [x + '_OHE' for x in feature_col]\n",
    "\n",
    "\n",
    "# assemble all the feature columns\n",
    "vecAssembler = VectorAssembler(inputCols=oheOutputCols, outputCol='features')\n",
    "df_h1 = vecAssembler.transform(trainingData)\n",
    "\n",
    "lr = LogisticRegression(featuresCol = 'features',labelCol='address_city_Index',\n",
    "                        maxIter=100, regParam=0.3, elasticNetParam=0)\n",
    "lrPipeline = Pipeline(stages = [vecAssembler,lr])\n",
    "lrModel = lrPipeline.fit(trainingData)\n",
    "\n",
    "def evaluate_h1(data):\n",
    "    print(lrModel)\n",
    "    print(lr.getRegParam())\n",
    "    vecData = vecAssembler.transform(data)\n",
    "    predictions = lrModel.transform(vecData)\n",
    "    predictions.\\\n",
    "        select('national_identifier', 'probability', 'address_city_Index','prediction').\\\n",
    "        orderBy('probability',ascending=False).show(n=5,truncate=30)\n",
    "    \n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol='address_city_Index',predictionCol='prediction')\n",
    "    lrAcc = evaluator.evaluate(predictions)\n",
    "    print('test accuracy = ',lrAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------------------+------------------+----------+\n",
      "|national_identifier|                   probability|address_city_Index|prediction|\n",
      "+-------------------+------------------------------+------------------+----------+\n",
      "|        49636475318|[0.9981634158524352,1.26612...|               0.0|       0.0|\n",
      "|        29641925480|[0.9951736834914906,4.32659...|               0.0|       0.0|\n",
      "|        44974414456|[0.9947927854059504,4.02437...|               0.0|       0.0|\n",
      "|        51211204220|[0.9936831228104824,0.00122...|               0.0|       0.0|\n",
      "|        52075005138|[0.9935156794485108,0.00159...|               0.0|       0.0|\n",
      "+-------------------+------------------------------+------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "test accuracy =  0.6278536819300573\n"
     ]
    }
   ],
   "source": [
    "lr.setRegParam(0.001)\n",
    "lrModel = lrPipeline.fit(trainingData)\n",
    "evaluate_h1(validData)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RegParam = 0.3\n",
    "\n",
    "Training Dataset Count:1789\n",
    "Vaildation Dataset Count:492\n",
    "Test Dataset Count:254\n",
    "LogisticRegressionModel: uid=LogisticRegression_0b17a9ea5e2c, numClasses=81, numFeatures=10027\n",
    "+-------------------+------------------------------+------+----------+\n",
    "|national_identifier|                   probability|labels|prediction|\n",
    "+-------------------+------------------------------+------+----------+\n",
    "|        49636475318|[0.8026008905582226,0.01378...|   0.0|       0.0|\n",
    "|        29641925480|[0.7636759520608256,0.01809...|   0.0|       0.0|\n",
    "|        44974414456|[0.7530555007256788,0.01807...|   0.0|       0.0|\n",
    "|        52075005138|[0.7474042692640681,0.03275...|   0.0|       0.0|\n",
    "|        51211204220|[0.7348430398985945,0.02854...|   0.0|       0.0|\n",
    "|        51091584238|[0.7269752731476222,0.02097...|   0.0|       0.0|\n",
    "|        29821982562|[0.6875031240913106,0.02322...|   0.0|       0.0|\n",
    "|        17267107090|[0.6655812404692909,0.02501...|   0.0|       0.0|\n",
    "|        23396115516|[0.6581262182685821,0.02765...|   0.0|       0.0|\n",
    "|        49693015298|[0.6489923252860343,0.02759...|   0.0|       0.0|\n",
    "+-------------------+------------------------------+------+----------+\n",
    "only showing top 10 rows\n",
    "\n",
    "test accuracy =  0.42873239096157856"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel.setRegParam(0.01)\n",
    "lrModel = lr.fit(trainingData)\n",
    "predictions = lrModel.transform(validData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------------------+------+----------+\n",
      "|national_identifier|                   probability|labels|prediction|\n",
      "+-------------------+------------------------------+------+----------+\n",
      "|        49636475318|[0.986710724245762,9.223238...|   0.0|       0.0|\n",
      "|        29641925480|[0.9747161839881305,0.00211...|   0.0|       0.0|\n",
      "|        44974414456|[0.9728858078534585,0.00206...|   0.0|       0.0|\n",
      "|        52075005138|[0.9691073561203233,0.00591...|   0.0|       0.0|\n",
      "|        51211204220|[0.9688285044137115,0.00479...|   0.0|       0.0|\n",
      "+-------------------+------------------------------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "test accuracy =  0.6049935385132912\n"
     ]
    }
   ],
   "source": [
    "predictions.\\\n",
    "        select('national_identifier', 'probability', 'labels','prediction').\\\n",
    "        orderBy('probability',ascending=False).show(n=5,truncate=30)\n",
    "    \n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='labels',predictionCol='prediction')\n",
    "lrAcc= evaluator.evaluate(predictions)\n",
    "print('test accuracy = ',lrAcc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RegParam = 0.01\n",
    "\n",
    "+-------------------+------------------------------+------+----------+\n",
    "|national_identifier|                   probability|labels|prediction|\n",
    "+-------------------+------------------------------+------+----------+\n",
    "|        49636475318|[0.986710724245762,9.223238...|   0.0|       0.0|\n",
    "|        29641925480|[0.9747161839881305,0.00211...|   0.0|       0.0|\n",
    "|        44974414456|[0.9728858078534585,0.00206...|   0.0|       0.0|\n",
    "|        52075005138|[0.9691073561203233,0.00591...|   0.0|       0.0|\n",
    "|        51211204220|[0.9688285044137115,0.00479...|   0.0|       0.0|\n",
    "+-------------------+------------------------------+------+----------+\n",
    "only showing top 5 rows\n",
    "\n",
    "test accuracy =  0.6049935385132912\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_h1(testData)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.01\n",
    "\n",
    "+-------------------+------------------------------+------+----------+\n",
    "|national_identifier|                   probability|labels|prediction|\n",
    "+-------------------+------------------------------+------+----------+\n",
    "|        12332476996|[0.9690483527018399,0.00257...|   0.0|       0.0|\n",
    "|        28064362124|[0.9681087604248593,0.00238...|   0.0|       0.0|\n",
    "|        41677285246|[0.9652404051624658,0.00294...|   0.0|       0.0|\n",
    "|        45640347474|[0.9628736882570113,0.00840...|   0.0|       0.0|\n",
    "|        55555498062|[0.954909879159928,0.004665...|   0.0|       0.0|\n",
    "+-------------------+------------------------------+------+----------+\n",
    "only showing top 5 rows\n",
    "\n",
    "test accuracy =  0.5834553575539898\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H2. Given all the information about one person, predict his/her gender.\n",
    "feature_col = ['first','last','mother_first','father_first','birth_city', 'year_of_birth','month_of_birth',\n",
    "               'id_registration_city', 'id_registration_district', 'address_city',\n",
    "               'address_district','address_neighborhood', 'street_address'\n",
    "               ]\n",
    "\n",
    "\n",
    "# All the feature columns\n",
    "oheOutputCols = [x + '_OHE' for x in feature_col]\n",
    "\n",
    "\n",
    "# assemble all the feature columns\n",
    "vecAssembler = VectorAssembler(inputCols=oheOutputCols, outputCol='features')\n",
    "# df_h2 = vecAssembler.transform(res)\n",
    "\n",
    "lr_h2 = LogisticRegression(featuresCol = 'features',labelCol='gender_Index',\n",
    "                        maxIter=100, regParam=0.3, elasticNetParam=0)\n",
    "lrPipeline_h2 = Pipeline(stages = [vecAssembler,lr_h2])\n",
    "lrModel_h2 = lrPipeline_h2.fit(trainingData)\n",
    "\n",
    "def evaluate_h2(data):\n",
    "    print('RegParam=',lrModel_h2.getRegParam())\n",
    "    predictions = lrModel_h2.transform(data)\n",
    "    predictions.\\\n",
    "        select('national_identifier', 'probability','gender','gender_Index','prediction').\\\n",
    "        orderBy('probability',ascending=False).show(n=10,truncate=30)\n",
    "    \n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol='gender_Index',predictionCol='prediction')\n",
    "    lrAcc = evaluator.evaluate(predictions)\n",
    "    print('test accuracy = ',lrAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineModel_2800379a94fe\n",
      "+-------------------+------------------------------+------+------------+----------+\n",
      "|national_identifier|                   probability|gender|gender_Index|prediction|\n",
      "+-------------------+------------------------------+------+------------+----------+\n",
      "|        63643167882|[0.9937419609106374,0.00625...|     K|         0.0|       0.0|\n",
      "|        14971091394|[0.9885102276275363,0.01148...|     K|         0.0|       0.0|\n",
      "|        31871182540|[0.985789077849872,0.014210...|     K|         0.0|       0.0|\n",
      "|        12026807310|[0.9844732109295973,0.01552...|     K|         0.0|       0.0|\n",
      "|        19364511572|[0.9791942119328154,0.02080...|     K|         0.0|       0.0|\n",
      "|        11804064914|[0.9771787586218412,0.02282...|     K|         0.0|       0.0|\n",
      "|        55636492460|[0.9763369474628155,0.02366...|     K|         0.0|       0.0|\n",
      "|        64681208308|[0.9759071351878916,0.02409...|     K|         0.0|       0.0|\n",
      "|        15940910302|[0.9731263680462484,0.02687...|     E|         1.0|       0.0|\n",
      "|        18103181182|[0.9725111032401041,0.02748...|     K|         0.0|       0.0|\n",
      "+-------------------+------------------------------+------+------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "test accuracy =  0.6809536372170353\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluate_h2(validData)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "regParam = 0.01\n",
    "\n",
    "+-------------------+------------------------------+------+------------+----------+\n",
    "|national_identifier|                   probability|gender|gender_Index|prediction|\n",
    "+-------------------+------------------------------+------+------------+----------+\n",
    "|        18557507132|[0.2272661289853091,0.77273...|     E|         1.0|       1.0|\n",
    "|        12026807310|[0.9881243477355919,0.01187...|     K|         0.0|       0.0|\n",
    "|        16049674478|[0.5917780790923316,0.40822...|     K|         0.0|       0.0|\n",
    "|        11411838434|[0.9680737398697784,0.03192...|     K|         0.0|       0.0|\n",
    "|        60535207558|[0.31780707217174475,0.6821...|     E|         1.0|       1.0|\n",
    "|        43876406200|[0.7696493376202568,0.23035...|     K|         0.0|       0.0|\n",
    "|        29662790876|[0.4811800054421304,0.51881...|     E|         1.0|       1.0|\n",
    "|        47110209374|[0.3859002825110793,0.61409...|     E|         1.0|       1.0|\n",
    "|        63643167882|[0.993255420422094,0.006744...|     K|         0.0|       0.0|\n",
    "|        15569780966|[0.97379538451849,0.0262046...|     K|         0.0|       0.0|\n",
    "+-------------------+------------------------------+------+------------+----------+\n",
    "only showing top 10 rows\n",
    "\n",
    "accuracy =  0.8658536585365855\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_h2.setRegParam(0.1)\n",
    "lrPipeline_h2 = Pipeline(stages = [vecAssembler,lr_h2])\n",
    "lrModel_h2 = lrPipeline_h2.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------------------+------+------------+----------+\n",
      "|national_identifier|                   probability|gender|gender_Index|prediction|\n",
      "+-------------------+------------------------------+------+------------+----------+\n",
      "|        28066584470|[0.10917065393999323,0.8908...|     E|         1.0|       1.0|\n",
      "|        10456467890|[0.9077924078473769,0.09220...|     K|         0.0|       0.0|\n",
      "|        45157719504|[0.2192069146574132,0.78079...|     E|         1.0|       1.0|\n",
      "|        39589937452|[0.18583600229712327,0.8141...|     E|         1.0|       1.0|\n",
      "|        15161744076|[0.1957294514261375,0.80427...|     E|         1.0|       1.0|\n",
      "|        23636482712|[0.06026563388594986,0.9397...|     E|         1.0|       1.0|\n",
      "|        36113066848|[0.1722213335203935,0.82777...|     E|         1.0|       1.0|\n",
      "|        53440491662|[0.9275128967501869,0.07248...|     K|         0.0|       0.0|\n",
      "|        29069307332|[0.772681859165467,0.227318...|     E|         1.0|       0.0|\n",
      "|        13676827314|[0.8848546431350095,0.11514...|     K|         0.0|       0.0|\n",
      "+-------------------+------------------------------+------+------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "accuracy =  0.862223949570754\n"
     ]
    }
   ],
   "source": [
    "evaluate_h2(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H3. 姓名预测模型：假设给定一个人的所有信息（除了姓名），预测这个人最可能的姓氏。分析该 模型Top1到 Top 5的预测准确度；\n",
    "\n",
    "feature_col = ['mother_first','father_first','birth_city','gender','year_of_birth','month_of_birth',\n",
    "               'id_registration_city', 'id_registration_district', 'address_city',\n",
    "               'address_district','address_neighborhood', 'street_address'\n",
    "               ]\n",
    "\n",
    "# 所有的特征列列名\n",
    "oheOutputCols = [x + '_OHE' for x in feature_col]\n",
    "\n",
    "# assemble all the feature columns\n",
    "vecAssembler = VectorAssembler(inputCols=oheOutputCols, outputCol='features')\n",
    "vecTrainDF_h3 = vecAssembler.transform(trainingData)\n",
    "trainingData.show(3)\n",
    "lr_h3 = LogisticRegression(featuresCol = 'features',labelCol='first_Index',\n",
    "                        maxIter=100, regParam=0.01, elasticNetParam=0)\n",
    "# lrPipeline_h3 = Pipeline(stages = [vecAssembler,lr_h3])\n",
    "lrModel_h3 = lr_h3.fit(vecTrainDF_h3)\n",
    "\n",
    "def evaluate_h3(data):\n",
    "    print(lrModel_h3)\n",
    "    vecData = vecAssembler.transform(data)\n",
    "    predictions = lrModel_h3.transform(vecData)\n",
    "    predictions.\\\n",
    "        select('national_identifier', 'probability', 'first','first_Index','prediction').\\\n",
    "        orderBy('probability',ascending=False).show(n=10,truncate=30)\n",
    "    \n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol='first_Index',predictionCol='prediction')\n",
    "    lrAcc = evaluator.evaluate(predictions)\n",
    "    print('test accuracy = ',lrAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "+-------------------+----------------------------+-------+------ ---+----------+\n",
    "|national_identifier |                  probability|   last|last_Index|prediction|\n",
    "+-------------------+----------------------------+-------+------- --+----------+\n",
    "|        34669954084|[0.0751656958984699,0.01306...|BAHADIR|     107.0|       0.0|\n",
    "|        51250399116|[0.01734398137692374,0.0140...|  TANKI|     345.0|      59.0|\n",
    "|        23258189716|[0.01582376988707977,0.0148...|   IRAK|     230.0|       0.0|\n",
    "|        14543163580|[0.015195940098257876,0.015...|  SENER|     331.0|       1.0|\n",
    "|        31243805398|[0.015019489320842194,0.015...| TURGUT|      52.0|       1.0|\n",
    "|        48322738614|[0.014916421279069685,0.014...| COSKUN|     150.0|      16.0|\n",
    "|        49633881822|[0.014897613581717132,0.015...|  KELES|      43.0|       1.0|\n",
    "|        40459256184|[0.012225633323033705,0.043...|  PEKAK|     311.0|       1.0|\n",
    "|        28873709622|[0.011274433627096122,0.015...| BAYRAM|     117.0|       1.0|\n",
    "|        16295109878|[0.010925602529400297,0.015...| YENICE|     393.0|       1.0|\n",
    "+-------------------+----------------------------+-------+----------+----------+\n",
    "only showing top 10 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy =  0.0\n"
     ]
    }
   ],
   "source": [
    "evaluate_h3(validData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_h3(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "|total|year|\n",
      "+-----+----+\n",
      "|    1|1888|\n",
      "|    2|1892|\n",
      "|   22|1897|\n",
      "|   27|1895|\n",
      "|   32|1896|\n",
      "|   48|1898|\n",
      "|   61|1894|\n",
      "|   66|1900|\n",
      "|   79|1901|\n",
      "|  108|1902|\n",
      "+-----+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # H4. 人口预测模型：统计每一年出生的人数，预测下一年新增人口数。\n",
    "df_h4 = df_format_date.withColumn('year_of_birth',year('date_of_birth'))\n",
    "df_population = df_h4.\\\n",
    "    select(\"year_of_birth\").\\\n",
    "    groupBy('year_of_birth').\\\n",
    "    agg(count('*').alias('total'))\n",
    "\n",
    "df_population = df_population.withColumn('year',df_population['year_of_birth'].cast('int')).drop('year_of_birth')\n",
    "df_population = df_population.filter(df_population['year'] > 1700)\n",
    "df_population.orderBy('total').show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(year=1888)\n",
      "+-------+----+-----+\n",
      "|  total|year|index|\n",
      "+-------+----+-----+\n",
      "| 785662|1959|   71|\n",
      "|1267087|1990|  102|\n",
      "|     32|1896|    8|\n",
      "|    113|1903|   15|\n",
      "|1097333|1975|   87|\n",
      "|1208944|1977|   89|\n",
      "|      1|1888|    0|\n",
      "|  82558|1924|   36|\n",
      "|      2|1892|    4|\n",
      "|1228686|1974|   86|\n",
      "| 132554|1927|   39|\n",
      "| 827701|1955|   67|\n",
      "|1256035|1978|   90|\n",
      "|  89810|1925|   37|\n",
      "|    717|1908|   20|\n",
      "| 765710|1961|   73|\n",
      "| 369836|1942|   54|\n",
      "| 305225|1939|   51|\n",
      "| 382879|1944|   56|\n",
      "|    118|1899|   11|\n",
      "+-------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def to_index(year):\n",
    "    return year-1888\n",
    "\n",
    "to_index_udf = udf(to_index, returnType=IntegerType())\n",
    "min_year = df_population.select(min('year').alias('year')).collect()[0]\n",
    "print(min_year)\n",
    "new_df = df_population.withColumn('index',to_index_udf(df_population['year']))\n",
    "new_df.show()\n",
    "\n",
    "(trianing, test) = new_df.randomSplit([0.8,0.2],seed = 2020)\n",
    "trianinging.persist()\n",
    "test.persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The formula for the linear regression lines is num = 15412.37*index-326171.48\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# from pyspark.ml.regression import LinearRegression\n",
    "# # from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "# vecAssembler = VectorAssembler(inputCols=['index'],outputCol='features')\n",
    "# vecTrainDF = vecAssembler.transform(trianing)\n",
    "# lr_h4 = LinearRegression(featuresCol='features',labelCol='total')\n",
    "\n",
    "# lrModel_h4 = lr_h4.fit(vecTrainDF)\n",
    "# m = lrModel_h4.coefficients[0]\n",
    "# b = lrModel_h4.intercept\n",
    "print(f\"\"\"The formula for the linear regression lines is num = {m:.2f}*index{b:.2f}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+--------+------------------+\n",
      "|  total|year|index|features|        prediction|\n",
      "+-------+----+-----+--------+------------------+\n",
      "|1242772|1987|   99|  [99.0]|1199653.5968508604|\n",
      "|1250520|1983|   95|  [95.0]|1138004.0989916562|\n",
      "| 976960|1969|   81|  [81.0]| 922230.8564844418|\n",
      "|1011805|1964|   76|  [76.0]| 845168.9841604368|\n",
      "| 827839|1956|   68|  [68.0]| 721869.9884420284|\n",
      "+-------+----+-----+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vecTestDF = vecAssembler.transform(test)\n",
    "predictions = lrModel_h4.transform(vecTestDF)\n",
    "predictions.orderBy('prediction',ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is 0.9323408621730506\n"
     ]
    }
   ],
   "source": [
    "regresssionEvaluator = RegressionEvaluator(predictionCol='prediction',labelCol='total', metricName='r2')\n",
    "r2 = regresssionEvaluator.evaluate(predictions)\n",
    "print(f\"r2 is {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+---------+\n",
      "|  total|year|index| logTotal|\n",
      "+-------+----+-----+---------+\n",
      "| 785662|1959|   71|13.574282|\n",
      "|1267087|1990|  102|14.052231|\n",
      "|     32|1896|    8| 3.465736|\n",
      "|    113|1903|   15| 4.727388|\n",
      "|1097333|1975|   87|13.908393|\n",
      "|1208944|1977|   89|14.005258|\n",
      "|      1|1888|    0|      0.0|\n",
      "|  82558|1924|   36|11.321257|\n",
      "|      2|1892|    4|0.6931472|\n",
      "|1228686|1974|   86|14.021456|\n",
      "| 132554|1927|   39|11.794745|\n",
      "| 827701|1955|   67|13.626408|\n",
      "|1256035|1978|   90| 14.04347|\n",
      "|  89810|1925|   37|11.405452|\n",
      "|    717|1908|   20|6.5750756|\n",
      "| 765710|1961|   73|13.548559|\n",
      "| 369836|1942|   54|12.820815|\n",
      "| 305225|1939|   51|12.628804|\n",
      "| 382879|1944|   56|12.855474|\n",
      "|    118|1899|   11|4.7706847|\n",
      "+-------+----+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.sql.types import FloatType\n",
    "from math import log\n",
    "\n",
    "def log_num(num):\n",
    "    if num:\n",
    "        return log(num)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "log_num_udf = udf(log_num, returnType=FloatType())\n",
    "log_df = new_df.withColumn('logTotal',log_num_udf(new_df['total']))\n",
    "log_df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The formula for the linear regression lines is log(num) = 0.10648180411118631*index5.356513516286501\n",
      "+-------+----+-----+---------+--------+------------------+\n",
      "|  total|year|index| logTotal|features|        prediction|\n",
      "+-------+----+-----+---------+--------+------------------+\n",
      "|1242772|1987|   99|14.032855|  [99.0]|15.898212123293947|\n",
      "|1250520|1983|   95| 14.03907|  [95.0]|  15.4722849068492|\n",
      "| 976960|1969|   81|13.792201|  [81.0]|13.981539649292593|\n",
      "|1011805|1964|   76|13.827247|  [76.0]|13.449130628736661|\n",
      "| 827839|1956|   68|13.626574|  [68.0]| 12.59727619584717|\n",
      "| 699374|1954|   66|13.457941|  [66.0]|12.384312587624798|\n",
      "| 610742|1953|   65| 13.32243|  [65.0]|12.277830783513611|\n",
      "| 663528|1950|   62|13.405326|  [62.0]|11.958385371180054|\n",
      "| 544884|1949|   61|13.208328|  [61.0]|11.851903567068867|\n",
      "| 442640|1947|   59|13.000512|  [59.0]|11.638939958846493|\n",
      "+-------+----+-----+---------+--------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "r2 is 0.8130096202685115\n"
     ]
    }
   ],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=['index'],outputCol='features')\n",
    "lr_h4_log = LinearRegression(featuresCol='features',labelCol='logTotal')\n",
    "\n",
    "training_log = trianing.withColumn('logTotal',log_num_udf('total'))\n",
    "vecTrainDF_log = vecAssembler.transform(training_log)\n",
    "lrModel_h4_log = lr_h4_log.fit(vecTrainDF_log)\n",
    "m_log = lrModel_h4_log.coefficients[0]\n",
    "b_log = lrModel_h4_log.intercept\n",
    "print(f\"\"\"The formula for the linear regression lines is log(total) = {m_log:.3f}*index+{b_log.3f}\"\"\")\n",
    "\n",
    "# test\n",
    "test_log = test.withColumn('logTotal',log_num_udf('total'))\n",
    "vecTestDF_log = vecAssembler.transform(test_log)\n",
    "predictions_log = lrModel_h4_log.transform(vecTestDF_log)\n",
    "predictions_log.orderBy('prediction',ascending=False).show(10)\n",
    "\n",
    "\n",
    "\n",
    "regresssionEvaluator = RegressionEvaluator(predictionCol='prediction',labelCol='logTotal', metricName='r2')\n",
    "r2_log = regresssionEvaluator.evaluate(predictions_log)\n",
    "print(f\"r2 is {r2_log}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
